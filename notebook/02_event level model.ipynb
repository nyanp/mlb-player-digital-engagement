{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc965dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "\n",
    "from src.parser import *\n",
    "from src.train import *\n",
    "from src.split import TimeSeriesSplit\n",
    "from src.event_level_model import prep_events\n",
    "from src.dataset_helper import *\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"[{name}] {elapsed:.3f}s\")\n",
    "    \n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "DATA_DIR = '../input/mlb-player-digital-engagement-forecasting'\n",
    "ARTIFACT_DIR = 'artifacts'\n",
    "USE_UPDATED = True\n",
    "\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = make_df_base_from_train_engagement(load_subdata(DATA_DIR, 'nextDayPlayerEngagement', USE_UPDATED))\n",
    "events = load_subdata(DATA_DIR, 'events', USE_UPDATED)\n",
    "rosters = load_subdata(DATA_DIR, 'rosters', USE_UPDATED)\n",
    "players = pd.read_csv(os.path.join(DATA_DIR, 'players.csv'))\n",
    "\n",
    "rosters['dailyDataDate'] = pd.to_datetime(rosters['dailyDataDate'], format='%Y%m%d')\n",
    "\n",
    "print(len(base_df))\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a98489",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_stacked = prep_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(events_stacked, base_df, how='left', on=['dailyDataDate', 'playerId'])\n",
    "merged = merged[~merged['target1'].isnull()]\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c022aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'mae',\n",
    "    'metrics': 'mae',\n",
    "    'num_leaves': 256,\n",
    "    'max_depth': 16,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "splits = [\n",
    "    (('2018-01-01', '2018-05-01'), ('2018-05-01', '2018-06-01')),\n",
    "    (('2018-01-01', '2018-06-01'), ('2018-06-01', '2018-07-01')),\n",
    "    (('2018-01-01', '2018-07-01'), ('2018-07-01', '2018-08-01')),\n",
    "    (('2018-01-01', '2018-08-01'), ('2018-08-01', '2019-01-01')),\n",
    "    (('2018-01-01', '2019-01-01'), ('2019-01-01', '2019-08-01')),\n",
    "    (('2018-01-01', '2019-08-01'), ('2019-08-01', '2020-01-01')),\n",
    "    (('2018-01-01', '2020-01-01'), ('2020-01-01', '2020-08-01')),\n",
    "    (('2018-01-01', '2020-08-01'), ('2020-08-01', '2021-04-01')),\n",
    "    (('2018-01-01', '2021-04-01'), ('2021-04-01', '2022-01-01')),\n",
    "]\n",
    "\n",
    "d_base = merged[['dailyDataDate', 'playerId', 'teamId']].copy()\n",
    "\n",
    "aggregated_features = []\n",
    "agg_g_features = []\n",
    "agg_t_features = []\n",
    "\n",
    "for tgt in ['target1', 'target2', 'target3', 'target4']:\n",
    "    X = merged.drop(['target1', 'target2', 'target3', 'target4', 'dailyDataDate', 'playerId', 'teamId'], axis=1).astype(np.float32)\n",
    "    y = merged[tgt]\n",
    "    \n",
    "    tgt_mask = ~y.isnull()\n",
    "\n",
    "    cv = TimeSeriesSplit('dailyDataDate', splits)\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(cv.split(merged)):\n",
    "        X_tr, X_va = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_tr, y_va = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        # drop null training data\n",
    "        tr_is_null = y_tr.isnull()\n",
    "        va_is_null = y_va.isnull()\n",
    "        \n",
    "        X_tr = X_tr[~tr_is_null]\n",
    "        y_tr = y_tr[~tr_is_null]\n",
    "        \n",
    "        print(f'fold {i} tr: {len(X_tr)}, va: {len(X_va)}')\n",
    "        model.fit(X_tr, y_tr, categorical_feature=['atBatEvent', 'event', 'menOnBase', 'gameType', 'pitchType', 'call'])\n",
    "        \n",
    "        oof[valid_index] = model.predict(X_va)\n",
    "        \n",
    "        mae = mean_absolute_error(y_va[~va_is_null], oof[valid_index][~va_is_null])\n",
    "        \n",
    "        print(f\"{tgt} fold {i} : {mae}\")\n",
    "        \n",
    "\n",
    "    d_base['oof'] = oof\n",
    "    aggregated = d_base.groupby(['dailyDataDate', 'playerId'])['oof'].agg(['min', 'max', 'mean']).reset_index()\n",
    "    aggregated.columns = ['dailyDataDate', 'playerId', f'events_oof_{tgt}_min', f'events_oof_{tgt}_max', f'events_oof_{tgt}_mean']\n",
    "    \n",
    "    aggregated_features.append(aggregated)\n",
    "\n",
    "    aggregated2 = d_base.groupby(['dailyDataDate'])['oof'].agg(['max', 'mean']).reset_index()\n",
    "    aggregated2.columns = ['dailyDataDate', f'events_oof_{tgt}_g_max', f'events_oof_{tgt}_g_mean']\n",
    "\n",
    "    agg_g_features.append(aggregated2)\n",
    "\n",
    "    aggregated3 = d_base.groupby(['dailyDataDate', 'teamId'])['oof'].agg(['max', 'mean']).reset_index()\n",
    "    aggregated3.columns = ['dailyDataDate', 'teamId', f'events_oof_{tgt}_t_max', f'events_oof_{tgt}_t_mean']\n",
    "\n",
    "    agg_t_features.append(aggregated3)\n",
    "\n",
    "    model_path = os.path.join(ARTIFACT_DIR, f'meta_model_{tgt}.bin')\n",
    "    model.booster_.save_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_base = base_df[['dailyDataDate', 'playerId']].copy()\n",
    "o_base = pd.merge_asof(o_base, rosters[['playerId', 'dailyDataDate', 'teamId']], on='dailyDataDate', by='playerId')\n",
    "o_base['teamId'] = o_base['teamId'].fillna(-1).astype(int)\n",
    "\n",
    "# merge-asofが古いデータとマッチしすぎると、テストデータでの予測に学習期間のeventに対する予測が含まれてしまう。\n",
    "# プレー単位の記録がエンゲージメントに与える影響は短期と想定されるため、適当な期間で打ち切る\n",
    "tolerance=pd.Timedelta('30d')\n",
    "\n",
    "for agg in aggregated_features:\n",
    "    o_base = pd.merge_asof(o_base, agg, on='dailyDataDate', by='playerId', tolerance=tolerance)\n",
    "\n",
    "for agg in agg_g_features:\n",
    "    o_base = pd.merge(o_base, agg, on='dailyDataDate', how='left')\n",
    "\n",
    "for agg in agg_t_features:\n",
    "    agg['teamId'] = agg['teamId'].astype(int)\n",
    "    o_base = pd.merge(o_base, agg, on=['dailyDataDate', 'teamId'], how='left')\n",
    "    \n",
    "assert len(o_base) == len(base_df)\n",
    "\n",
    "o_base.drop(['dailyDataDate', 'playerId', 'teamId'], axis=1).to_feather(os.path.join(ARTIFACT_DIR, 'events_oof_asof_4tgt_3.f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}