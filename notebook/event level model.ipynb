{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import nyaggle\n",
    "from nyaggle.experiment import run_experiment\n",
    "import lightgbm as lgb\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "#sys.path.append('../')\n",
    "\n",
    "from src.feature import *\n",
    "from src.store import *\n",
    "from src.parser import *\n",
    "from src.train import *\n",
    "from src.event_level_model import prep_events\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"[{name}] {elapsed:.3f}s\")\n",
    "    \n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "DATA_DIR = '../input/mlb-player-digital-engagement-forecasting'\n",
    "OUTPUT_DIR = 'artifacts'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = make_df_base_from_train_engagement(pd.read_feather(os.path.join(DATA_DIR, 'train_nextDayPlayerEngagement_updated.f')))\n",
    "players = pd.read_csv(os.path.join(DATA_DIR, 'players.csv'))\n",
    "\n",
    "print(len(base_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa22635",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_DIR, 'train_events_updated.f')):\n",
    "    train = pd.read_feather(os.path.join(DATA_DIR, 'train_updated.f'))\n",
    "\n",
    "    eng = []\n",
    "    for i, row in tqdm(train.iterrows()):\n",
    "        try:\n",
    "            loaded = json.loads(row['events'])\n",
    "            for l in loaded:\n",
    "                l['dailyDataDate'] = row.date\n",
    "            eng.extend(loaded)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    events = pd.DataFrame(eng)\n",
    "    events.to_feather(os.path.join(DATA_DIR, 'train_events_updated.f'))\n",
    "    del train\n",
    "else:\n",
    "    events = pd.read_feather(os.path.join(DATA_DIR, 'train_events_updated.f'))\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd358b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_DIR, 'train_rosters_updated.f')):\n",
    "    train = pd.read_feather(os.path.join(DATA_DIR, 'train_updated.f'))\n",
    "\n",
    "    eng = []\n",
    "    for i, row in tqdm(train.iterrows()):\n",
    "        try:\n",
    "            loaded = json.loads(row['rosters'])\n",
    "            for l in loaded:\n",
    "                l['dailyDataDate'] = row.date\n",
    "            eng.extend(loaded)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    rosters = pd.DataFrame(eng)\n",
    "    rosters.to_feather(os.path.join(DATA_DIR, 'train_rosters_updated.f'))\n",
    "    del train\n",
    "else:\n",
    "    rosters = pd.read_feather(os.path.join(DATA_DIR, 'train_rosters_updated.f'))\n",
    "\n",
    "rosters['dailyDataDate'] = pd.to_datetime(rosters['dailyDataDate'], format='%Y%m%d')\n",
    "rosters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_stacked = prep_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_stacked['teamId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(events_stacked, base_df, how='left', on=['dailyDataDate', 'playerId'])\n",
    "merged = merged[~merged['target1'].isnull()]\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc38073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyaggle.validation import TimeSeriesSplit\n",
    "from nyaggle.experiment import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'mae',\n",
    "    'metrics': 'mae',\n",
    "    'num_leaves': 256,\n",
    "    'max_depth': 16,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "splits = [\n",
    "    (('2018-01-01', '2018-05-01'), ('2018-05-01', '2018-06-01')),\n",
    "    (('2018-01-01', '2018-06-01'), ('2018-06-01', '2018-07-01')),\n",
    "    (('2018-01-01', '2018-07-01'), ('2018-07-01', '2018-08-01')),\n",
    "    (('2018-01-01', '2018-08-01'), ('2018-08-01', '2019-01-01')),\n",
    "    (('2018-01-01', '2019-01-01'), ('2019-01-01', '2019-08-01')),\n",
    "    (('2018-01-01', '2019-08-01'), ('2019-08-01', '2020-01-01')),\n",
    "    (('2018-01-01', '2020-01-01'), ('2020-01-01', '2020-08-01')),\n",
    "    (('2018-01-01', '2020-08-01'), ('2020-08-01', '2021-04-01')),\n",
    "    (('2018-01-01', '2021-04-01'), ('2021-04-01', '2022-01-01')),\n",
    "]\n",
    "\n",
    "d_base = merged[['dailyDataDate', 'playerId', 'teamId']].copy()\n",
    "\n",
    "aggregated_features = []\n",
    "agg_g_features = []\n",
    "agg_t_features = []\n",
    "\n",
    "for tgt in ['target1', 'target2']:\n",
    "    X = merged.drop(['target1', 'target2', 'target3', 'target4', 'dailyDataDate', 'playerId', 'teamId'], axis=1).astype(np.float32)\n",
    "    y = merged[tgt]\n",
    "\n",
    "    cv = TimeSeriesSplit('dailyDataDate', splits)\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(cv.split(merged)):\n",
    "        X_tr, X_va = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_tr, y_va = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        print(f'fold {i} tr: {len(X_tr)}, va: {len(X_va)}')\n",
    "        model.fit(X_tr, y_tr, categorical_feature=['atBatEvent', 'event', 'menOnBase', 'gameType', 'pitchType', 'call'])\n",
    "        \n",
    "        oof[valid_index] = model.predict(X_va)\n",
    "        \n",
    "        mae = mean_absolute_error(y_va, oof[valid_index])\n",
    "        \n",
    "        print(f\"{tgt} fold {i} : {mae}\")\n",
    "        \n",
    "\n",
    "    d_base['oof'] = oof\n",
    "    aggregated = d_base.groupby(['dailyDataDate', 'playerId'])['oof'].agg(['min', 'max', 'mean']).reset_index()\n",
    "    aggregated.columns = ['dailyDataDate', 'playerId', f'events_oof_{tgt}_min', f'events_oof_{tgt}_max', f'events_oof_{tgt}_mean']\n",
    "    \n",
    "    aggregated_features.append(aggregated)\n",
    "\n",
    "    aggregated2 = d_base.groupby(['dailyDataDate'])['oof'].agg(['max', 'mean']).reset_index()\n",
    "    aggregated2.columns = ['dailyDataDate', f'events_oof_{tgt}_g_max', f'events_oof_{tgt}_g_mean']\n",
    "\n",
    "    agg_g_features.append(aggregated2)\n",
    "\n",
    "    aggregated3 = d_base.groupby(['dailyDataDate', 'teamId'])['oof'].agg(['max', 'mean']).reset_index()\n",
    "    aggregated3.columns = ['dailyDataDate', 'teamId', f'events_oof_{tgt}_t_max', f'events_oof_{tgt}_t_mean']\n",
    "\n",
    "    agg_t_features.append(aggregated3)\n",
    "\n",
    "    model_path = os.path.join(OUTPUT_DIR, f'meta_model_{tgt}.bin')\n",
    "    model.booster_.save_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c27d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_base = base_df[['dailyDataDate', 'playerId']].copy()\n",
    "o_base = pd.merge_asof(o_base, rosters[['playerId', 'dailyDataDate', 'teamId']], on='dailyDataDate', by='playerId')\n",
    "o_base['teamId'] = o_base['teamId'].fillna(-1).astype(int)\n",
    "\n",
    "for agg in aggregated_features:\n",
    "    o_base = pd.merge_asof(o_base, agg, on='dailyDataDate', by='playerId')\n",
    "\n",
    "for agg in agg_g_features:\n",
    "    o_base = pd.merge(o_base, agg, on='dailyDataDate', how='left')\n",
    "\n",
    "for agg in agg_t_features:\n",
    "    agg['teamId'] = agg['teamId'].astype(int)\n",
    "    o_base = pd.merge_asof(o_base, agg, on='dailyDataDate', by='teamId')\n",
    "    \n",
    "assert len(o_base) == len(base_df)\n",
    "\n",
    "o_base.drop(['dailyDataDate', 'playerId', 'teamId'], axis=1).to_feather(os.path.join(OUTPUT_DIR, 'events_oof_asof.f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_base = base_df[['dailyDataDate', 'playerId']].copy()\n",
    "o_base = pd.merge_asof(o_base, rosters[['playerId', 'dailyDataDate', 'teamId']], on='dailyDataDate', by='playerId')\n",
    "o_base['teamId'] = o_base['teamId'].fillna(-1).astype(int)\n",
    "\n",
    "# merge-asofが古いデータとマッチしすぎると、テストデータでの予測に学習期間のeventに対する予測が含まれてしまう。\n",
    "# プレー単位の記録がエンゲージメントに与える影響は短期と想定されるため、適当な期間で打ち切る\n",
    "tolerance=pd.Timedelta('30d')\n",
    "\n",
    "for agg in aggregated_features:\n",
    "    o_base = pd.merge_asof(o_base, agg, on='dailyDataDate', by='playerId', tolerance=tolerance)\n",
    "\n",
    "for agg in agg_g_features:\n",
    "    o_base = pd.merge(o_base, agg, on='dailyDataDate', how='left')\n",
    "\n",
    "for agg in agg_t_features:\n",
    "    agg['teamId'] = agg['teamId'].astype(int)\n",
    "    o_base = pd.merge(o_base, agg, on=['dailyDataDate', 'teamId'], how='left')\n",
    "    \n",
    "assert len(o_base) == len(base_df)\n",
    "\n",
    "o_base.drop(['dailyDataDate', 'playerId', 'teamId'], axis=1).to_feather(os.path.join(OUTPUT_DIR, 'events_oof_asof_2.f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
